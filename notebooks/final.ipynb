{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image PreProcessing\n",
    "### 1. Resizing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizer(img):\n",
    "    scale_percent = 60 # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    # resize image\n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Contouring and finding its side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_changer(thresh):\n",
    "    img,cont, hier = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sort=sorted(cont,key=cv2.contourArea,reverse=True)\n",
    "    biggest=sort[1]\n",
    "    top_left,_=min(enumerate([i[0][0]+i[0][1] for i in biggest]),key=operator.itemgetter(1))\n",
    "    top_right,_=max(enumerate([i[0][0]-i[0][1] for i in biggest]),key=operator.itemgetter(1))\n",
    "    bottom_left,_=min(enumerate([i[0][0]-i[0][1] for i in biggest]),key=operator.itemgetter(1))\n",
    "    bottom_right,_=max(enumerate([i[0][0]+i[0][1] for i in biggest]),key=operator.itemgetter(1))\n",
    "    corner=biggest[top_left][0],biggest[top_right][0],biggest[bottom_right][0],biggest[bottom_left][0]\n",
    "    return corner\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(line1,line2):\n",
    "    x=line2[0]-line1[0]\n",
    "    y=line2[1]-line1[1]\n",
    "    return np.sqrt((x**2)+(y**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extracting the cropped image and its coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def side_finder(thresh,top_left,top_right,bottom_right,bottom_left):\n",
    "    sides=max([distance(top_left,top_right),distance(top_right,bottom_right),distance(bottom_left,bottom_right),distance(top_left,bottom_left)])\n",
    "    source=np.array([top_left,top_right,bottom_right,bottom_left],np.float32)\n",
    "    destination=np.array([(0,0),(sides-1,0),(sides-1,sides-1),(0,sides-1)],np.float32)\n",
    "    matrix1=cv2.getPerspectiveTransform(source,destination)\n",
    "    cropped=cv2.warpPerspective(thresh,matrix1,(int(sides),int(sides)))\n",
    "    cell_coord=gridcoordinates(cropped)\n",
    "    ret,inv_matrix=cv2.invert(matrix1)\n",
    "#   transformed_points = cv2.warpPerspective(cropped,inv_matrix, (thresh.shape[]), cv2.WARP_INVERSE_MAP)\n",
    "    array=[cropped,inv_matrix]\n",
    "    return array\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridcoordinates(square):\n",
    "    cell_coordinate=np.zeros((81,4),np.float32)\n",
    "    grid_size=square.shape[:1]\n",
    "    cell=grid_size[0]/9\n",
    "    k=0\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            x1,y1=(i*cell,j*cell)\n",
    "            x2,y2=((i+1)*cell,(j+1)*cell)\n",
    "            cell_coordinate[k,:]=[x1,y1,x2,y2]\n",
    "            k+=1\n",
    "    return cell_coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(img,coord):\n",
    "    x1, y1, x2, y2=coord\n",
    "    dig=img[int(x1):int(x2), int(y1):int(y2)]# taking the value of coorsinates of a box\n",
    "    dig3=cv2.resize(dig, (45, 45), interpolation=cv2.INTER_CUBIC)#resizing to the hight 45 and width 45\n",
    "    digit=dig3/np.max(dig3)#scaling to makie the value between 0 and 1\n",
    "    return digit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digiter(cropped,cell_coord):\n",
    "    total_digit=np.zeros((81,45,45),np.float32)\n",
    "    for i in range(0,cell_coord.shape[0]):\n",
    "        digit=extraction(cropped,cell_coord[i,:])\n",
    "        total_digit[i,:,:]=digit\n",
    "    total_digit=total_digit.reshape(-1,45,45,1)    \n",
    "    return total_digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction and evaluation\n",
    "### 1.Predicting the digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(total_digit):    \n",
    "    hist=load_model(\"Newmodel_train.h5\")\n",
    "    pred=hist.predict(total_digit)>0.9\n",
    "    pred=pred.argmax(1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(pred):\n",
    "    list_values=list(pred)\n",
    "    matrix=rearange_list(list_values)\n",
    "    matrix_p=np.copy(matrix)\n",
    "    cache=[matrix,matrix_p]\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearange_list(nlist):\n",
    "    dlist=[]\n",
    "    for i in range(0, 9):\n",
    "        k=9*i\n",
    "        l=k+9\n",
    "        sub_list=nlist[k:l]\n",
    "        dlist.append(sub_list)\n",
    "    return np.matrix(dlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Backtracking Algorithm Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_possile_value(x, y, n, grid):\n",
    "    for i in range(0, 9):\n",
    "        if grid[x, i]==n:\n",
    "            return False\n",
    "        \n",
    "    for i in range(0, 9):\n",
    "        if grid[i, y]==n:\n",
    "            return False\n",
    "    x0=(x//3)*3\n",
    "    y0=(y//3)*3\n",
    "    for i in range(0, 3):\n",
    "        for j in range(0, 3):\n",
    "            if grid[x0+i, y0+j]==n:\n",
    "                return False\n",
    "            \n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "#fill in the empty slots:\n",
    "def grid_solver(grid):\n",
    "    for x in range(9):\n",
    "        for y in range(9):\n",
    "            if grid[x, y]==0:\n",
    "                for n in range(1, 10):\n",
    "                    if verify_possile_value(x, y, n, grid):\n",
    "                        grid[x, y]=n\n",
    "                        result=grid_solver(grid)\n",
    "                        \n",
    "                        if result is not None:\n",
    "                            return result\n",
    "                        \n",
    "                        grid[x, y]=0 #Backtracking\n",
    "                return None               \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Virtual Image Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def virtualimager(cropped,result,pred,coordinates):\n",
    "    virtual_image=np.zeros((cropped.shape[0],cropped.shape[1],3),dtype=np.uint8)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            if prediction(pred)[1][j,i]==0:\n",
    "                number=result[j,i]\n",
    "                corr=coordinates[i,j]\n",
    "                xc=int((corr[0]+corr[2])/2)\n",
    "                yc=int((corr[1]+corr[3])/2)\n",
    "                virtual_image=cv2.putText(virtual_image,str(number),(xc-4,yc+4),font,0.9,(0,255,0),2)\n",
    "    return virtual_image           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 0 0 0 4 0 8 6 0]\n",
      " [4 0 5 0 0 6 0 0 1]\n",
      " [1 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 9 1 0 0 0 0]\n",
      " [0 4 0 0 0 0 0 5 0]\n",
      " [0 0 0 0 5 7 0 0 0]\n",
      " [0 0 0 0 0 5 0 0 3]\n",
      " [5 0 0 1 0 0 9 0 8]\n",
      " [0 2 3 0 8 0 0 0 7]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# while True:\n",
    "#     ret,frame= cap.read()\n",
    "frame = cv2.imread('sudko.jpg')\n",
    "gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "corner=image_changer(thresh)\n",
    "\n",
    "cv2.imshow(\"cont\",frame)\n",
    "\n",
    "top_left,top_right,bottom_right,bottom_left=corner\n",
    "sider=side_finder(thresh,top_left,top_right,bottom_right,bottom_left)\n",
    "\n",
    "cell_coord=gridcoordinates(sider[0])\n",
    "coordinates=cell_coord.reshape(9,9,4)\n",
    "\n",
    "image_digit=digiter(sider[0],cell_coord)\n",
    "\n",
    "pred=model(image_digit)\n",
    "\n",
    "mat = prediction(pred)\n",
    "\n",
    "print(mat[0])\n",
    "result=grid_solver(mat[0])\n",
    "\n",
    "# if result is None:\n",
    "#     continue\n",
    "# else:\n",
    "    \n",
    "virtualimage=virtualimager(sider[0],result,pred,coordinates)\n",
    "\n",
    "gray1=cv2.cvtColor(virtualimage,cv2.COLOR_BGR2GRAY)\n",
    "vimg=cv2.warpPerspective(gray1,sider[1], (frame.shape[1],frame.shape[0]), cv2.WARP_INVERSE_MAP)\n",
    "gray2=cv2.cvtColor(vimg,cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "frame = cv2.addWeighted(gray2,1,frame,0.8,0)\n",
    "\n",
    "cv2.imshow(\"cont1\",frame)\n",
    "cv2.waitKey()\n",
    "#     if(cv2.waitKey(20) & 0xFF==ord('q')):\n",
    "#         cap.release()\n",
    "#         break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
